{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First things first\n",
    "Let's see if we can connect to the service we have deployed through AutoML..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://1a88cd84-f73c-44fb-bd71-a2b0e8ccd881.westus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Webservice\n",
    "from azureml.core import Model\n",
    "\n",
    "#Load workspace\n",
    "ws = Workspace.from_config(path=\".file-path/ws_config.json\") #I have no idea where that path value has come from, but it works\n",
    "\n",
    "#Load services available in this workspace\n",
    "services = Webservice.list(ws)\n",
    "classification_service = services[0]\n",
    "print(classification_service.scoring_uri)\n",
    "#print(classification_service.get_keys()) #Authentication is disabled by default, so this will crash and burn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! That's a decent start. Now I'm guessing I can use that scoring URL to do my test predictions without having to load the model into here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by configuring a simple JSON object to send up in the request. I sure hope there's an easy way to build this request object from a CSV / dataframe... guess we'll soon find out!  \n",
    "Now which features did I train on again...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"data\":\n",
    "        [\n",
    "            [\n",
    "                'Fremont',\n",
    "                'California',\n",
    "                'United States',\n",
    "                '1/05/1945',\n",
    "                'Bachelors',\n",
    "                'Management',\n",
    "                'F',\n",
    "                'S',\n",
    "                0,\n",
    "                2,\n",
    "                0,\n",
    "                5,\n",
    "                86931   \n",
    "            ]          \n",
    "        ]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That'll do for now... let's see if we can call it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_response(req_data):\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    response = requests.post(classification_service.scoring_uri, req_data, headers=headers)\n",
    "    return response\n",
    "\n",
    "request_data = json.dumps(data)\n",
    "response = get_response(request_data)\n",
    "response_data = json.loads(json.loads(response.text)) #Bit odd that we need to double up on the loads function, but it comes back as a string otherwise\n",
    "print(response_data['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yusss.... okay we have a response! That's kind of awesome!  \n",
    "I don't know whether that zero is the classification result, or just a weird response code though. Better try again with some more data :)  \n",
    "We have been supplied with a set of 500 observations that the model has not seen before. I have already mangled the CSV so that the feature columns we ignored during training have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '0', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '1', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "#Load rows from test set in CSV. Convert to lists, serialise as JSON, and send it off.\n",
    "import pandas as pd\n",
    "\n",
    "test_values = pd.read_csv('AW_Classification_Test.csv')\n",
    "test_data = test_values.values.tolist()\n",
    "\n",
    "data = {\"data\": test_data }\n",
    "request_data = json.dumps(data)\n",
    "response = get_response(request_data)\n",
    "response_data = json.loads(json.loads(response.text)) #Bit odd that we need to double up on the loads function, but it comes back as a string otherwise\n",
    "print(response_data['result'])\n",
    "\n",
    "response_data_frame = pd.DataFrame(response_data['result'])\n",
    "response_data_frame.shape\n",
    "pd.DataFrame(response_data['result']).to_csv(\"AW_Classification_Results.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That definitely looks like a set of classification results :)  \n",
    "What do we get when we feed it into the grading sheet?  \n",
    "![alt text](result.PNG \"Grading sheet accuracy result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy heck! 80% accuracy, with what must have been about 2 hours work all up (most of that sitting around waiting for training and deployments to complete).  \n",
    "Next step? Is to follow the manual process and see if I can at least match that myself :D  \n",
    "Another thing I would like to try is to load the model and work against it directly in a notebook - that way I'm not dependent on my expensive Azure services to be running to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
